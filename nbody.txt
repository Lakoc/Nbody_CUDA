Paralelní programování na GPU (PCG 2022)
Projekt c. 1 (cuda)
Login: xpolok03

Krok 0: základní implementace
=============================
i           Velikost dat    	čas jedne iterace [s]
10          N: 25600            Time: 0.009681 s
11          N: 28160            Time: 0.010645 s
12          N: 30720            Time: 0.011614 s
13          N: 33280            Time: 0.012587 s
14          N: 35840            Time: 0.013547 s
15          N: 38400            Time: 0.014514 s
16          N: 40960            Time: 0.015477 s
17          N: 43520            Time: 0.016444 s
18          N: 46080            Time: 0.017410 s
19          N: 48640            Time: 0.018374 s
20          N: 51200            Time: 0.019338 s
21          N: 53760            Time: 0.020309 s
22          N: 56320            Time: 0.029949 s
23          N: 58880            Time: 0.031323 s
24          N: 61440            Time: 0.032808 s
25          N: 64000            Time: 0.034268 s


Vyskytlo se něco neočekávaného v naměřených časech  
Pokud ano, vysvětlete:

Grafická karta Nvidia A100 na clusteru Karolina disponuje 108 SM jednotkami.
Dle zadání blok disponuje 512 vlákny, tudiž vstup o velikosti N=53760 se namapuje na 105 bloků, což vede k dobrému využití (105/108) skoro všech SM jednotek a odpadá nutnost přepínání kontextu.
Naopak vstup o velikosti N=56320 se rozdělí na 110 bloků, což nutně vede k tomu, že zbylé dva bloky musí čekat, až dojde k přepnutí kontextu, aby mohly zahájit svojí činnost, což vede k časové prodlevě.


Krok 1: optimalizace kódu
=====================
Došlo ke zrychlení?

Ano, došlo ke zrychlení cca 35% oproti původní verzi.

i           Velikost dat    	čas jedne iterace [s]
10          N: 25600            Time: 0.006461 s
11          N: 28160            Time: 0.007102 s
12          N: 30720            Time: 0.007748 s
13          N: 33280            Time: 0.008392 s
14          N: 35840            Time: 0.009031 s
15          N: 38400            Time: 0.009679 s
16          N: 40960            Time: 0.010321 s
17          N: 43520            Time: 0.010961 s
18          N: 46080            Time: 0.011605 s
19          N: 48640            Time: 0.012248 s
20          N: 51200            Time: 0.012891 s
21          N: 53760            Time: 0.013539 s
22          N: 56320            Time: 0.019427 s
23          N: 58880            Time: 0.020301 s
24          N: 61440            Time: 0.021237 s
25          N: 64000            Time: 0.022143 s


Popište hlavní důvody:

Odpadla nutnost synchronizace mezi kernely, taktéž došlo k lepšímu znovupoužití načtených hodnot v registrech.
Zároveň není nutné počítat veličiny jako vzdálenost na ose x,y, ... dvakrát.
Částice do sebe naražejí, nebo na sebe působí gravitační sílu - došlo tedy k omezení zbytečného kódu, kdy probíhal výpočet, avšak do vektoru rychlosti byla přiřazena 0.
Nyní je v obou případech přičtena nová rychlost a došlo k jistému snížení divergence vláken při zapsání výsledků (2x2->2).

Krok 2: sdílená paměť
=====================
Došlo ke zrychlení?

Ano, došlo k dalšímu zrychlení, cca 10%.

i           Velikost dat    	čas jedne iterace [s]
10          N: 25600            Time: 0.004725 s
11          N: 28160            Time: 0.005193 s
12          N: 30720            Time: 0.005663 s
13          N: 33280            Time: 0.006132 s
14          N: 35840            Time: 0.006598 s
15          N: 38400            Time: 0.007068 s
16          N: 40960            Time: 0.007536 s
17          N: 43520            Time: 0.008007 s
18          N: 46080            Time: 0.008473 s
19          N: 48640            Time: 0.008942 s
20          N: 51200            Time: 0.009411 s
21          N: 53760            Time: 0.009878 s
22          N: 56320            Time: 0.017790 s
23          N: 58880            Time: 0.018598 s
24          N: 61440            Time: 0.019410 s
25          N: 64000            Time: 0.020210 s

Zdůvodněte:

K zrychlení dochází kvůli tomu, že hodnoty jsou načteny do sdílené paměti. Ta se nachází přímo na čipu, což vede k paměťovým transakcím, které jsou mnohem rychlejší.


Krok 5: analýza výkonu
======================
N            čas CPU [s]    čas GPU [s]    propustnost paměti [MB/s]    výkon [MFLOPS]    zrychlení [-]     vláken/blok [-]
2048         0.057312       0.000383       172118.835020                231565.876291     149.64            128
4096         0.227922       0.000756       161402.988867                469240.058354     301.48            128
8192         0.910145       0.001507       155900.223857                940971.295509     603.94            128
16384        3.63661        0.003152       145286.868604                1792976.797289    1153.75           256
32768        14.546         0.007027       128908.811104                3226779.399985    2070.02           128
65536        58.1601        0.018751       96126.092471                 4836760.762754    3101.71           128
131072       232.677        0.069807       51487.935068                 5180199.309682    3333.15           256
262144       930.494        0.263188       27734.748926                 5495805.456708    3535.47           256
524288       4*930.494      0.990323       23673.917510                 5828235.045855    3758.35           1024
1048576      16*930.494     3.809705       147946.435254                6064947.392854    3907.89           512

Propustnosti a výkon GPU byly měřeny pomoci: https://gitlab.com/NERSC/roofline-on-nvidia-gpus/-/tree/roofline-hackathon-2020/

čas =  sm__cycles_elapsed.avg / sm__cycles_elapsed.avg.per_second

propustnost paměti = dram__bytes.sum.per_second / 1024

výkon = (2 * sm__sass_thread_inst_executed_op_dfma_pred_on.sum + sm__sass_thread_inst_executed_op_dmul_pred_on.sum + sm__sass_thread_inst_executed_op_dadd_pred_on.sum + 2 * sm__sass_thread_inst_executed_op_ffma_pred_on. + sm__sass_thread_inst_executed_op_fmul_pred_on.sum +
    + sm__sass_thread_inst_executed_op_fadd_pred_on.sum + 2 * sm__sass_thread_inst_executed_op_hfma_pred_on.sum + sm__sass_thread_inst_executed_op_hmul_pred_on.sum + sm__sass_thread_inst_executed_op_hadd_pred_on.sum + 512 * sm__inst_executed_pipe_tensor.sum) / čas / 1024 / 1024

Od jakého počtu částic se vyplatí počítat na grafické kartě?

Díky úpravám a zjedondušení výpočtu, se vyplatí počítat na grafické kartě již od nejmenšího počtu částic.

Krok 5: bonus - srovnání grafických karet
======================
N            čas GPU 1 [s]   propustnost 1 [MB/s]    výkon 1 [MFLOPS]   čas GPU 2 [s]  propustnost 2 [MB/s]    výkon 2 [MFLOPS]
2^n * 1024      ...            ...            ...          ...             ...               ...                    ...
    ...         ...            ...            ...          ...             ...               ...                    ...
    ...         ...            ...            ...          ...             ...               ...                    ...

Pro n 1 az 10

Porovnejte grafické karty z hlediska výkonu a propustnosti paměti.

===================================
