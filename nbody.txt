Paralelní programování na GPU (PCG 2022)
Projekt c. 1 (cuda)
Login: xpolok03

Krok 0: základní implementace
=============================
i           Velikost dat    	čas jedne iterace [s]
10          N: 25600            Time: 0.009681 s
11          N: 28160            Time: 0.010645 s
12          N: 30720            Time: 0.011614 s
13          N: 33280            Time: 0.012587 s
14          N: 35840            Time: 0.013547 s
15          N: 38400            Time: 0.014514 s
16          N: 40960            Time: 0.015477 s
17          N: 43520            Time: 0.016444 s
18          N: 46080            Time: 0.017410 s
19          N: 48640            Time: 0.018374 s
20          N: 51200            Time: 0.019338 s
21          N: 53760            Time: 0.020309 s
22          N: 56320            Time: 0.029949 s
23          N: 58880            Time: 0.031323 s
24          N: 61440            Time: 0.032808 s
25          N: 64000            Time: 0.034268 s


Vyskytlo se něco neočekávaného v naměřených časech  
Pokud ano, vysvětlete:

Grafická karta Nvidia A100 na clusteru Karolina disponuje 108 SM jednotkami.
Dle zadání blok disponuje 512 vlákny, tudiž vstup o velikosti N=53760 se namapuje na 105 bloků, což vede k dobrému využití (105/108) skoro všech SM jednotek a odpadá nutnost přepínání kontextu.
Naopak vstup o velikosti N=56320 se rozdělí na 110 bloků, což nutně vede k tomu, že zbylé dva bloky musí čekat, až dojde k přepnutí kontextu, aby mohly zahájit svojí činnost, což vede k časové prodlevě.


Krok 1: optimalizace kódu
=====================
Došlo ke zrychlení?

Ano, došlo ke zrychlení cca 35% oproti původní verzi.

i           Velikost dat    	čas jedne iterace [s]
10          N: 25600            Time: 0.006461 s
11          N: 28160            Time: 0.007102 s
12          N: 30720            Time: 0.007748 s
13          N: 33280            Time: 0.008392 s
14          N: 35840            Time: 0.009031 s
15          N: 38400            Time: 0.009679 s
16          N: 40960            Time: 0.010321 s
17          N: 43520            Time: 0.010961 s
18          N: 46080            Time: 0.011605 s
19          N: 48640            Time: 0.012248 s
20          N: 51200            Time: 0.012891 s
21          N: 53760            Time: 0.013539 s
22          N: 56320            Time: 0.019427 s
23          N: 58880            Time: 0.020301 s
24          N: 61440            Time: 0.021237 s
25          N: 64000            Time: 0.022143 s


Popište hlavní důvody:

Odpadla nutnost synchronizace mezi kernely, taktéž došlo k lepšímu znovupoužití načtených hodnot v registrech.
Zároveň není nutné počítat veličiny jako vzdálenost na ose x,y, ... dvakrát.
Částice do sebe naražejí, nebo na sebe působí gravitační sílu - došlo tedy k omezení zbytečného kódu, kdy probíhal výpočet, avšak do vektoru rychlosti byla přiřazena 0.
Nyní je v obou případech přičtena nová rychlost a došlo k jistému snížení divergence vláken při zapsání výsledků (2x2->2).

Krok 2: sdílená paměť
=====================
Došlo ke zrychlení?

Ano, došlo k dalšímu zrychlení, cca 10%.

i           Velikost dat    	čas jedne iterace [s]
10          N: 25600            Time: 0.004725 s
11          N: 28160            Time: 0.005193 s
12          N: 30720            Time: 0.005663 s
13          N: 33280            Time: 0.006132 s
14          N: 35840            Time: 0.006598 s
15          N: 38400            Time: 0.007068 s
16          N: 40960            Time: 0.007536 s
17          N: 43520            Time: 0.008007 s
18          N: 46080            Time: 0.008473 s
19          N: 48640            Time: 0.008942 s
20          N: 51200            Time: 0.009411 s
21          N: 53760            Time: 0.009878 s
22          N: 56320            Time: 0.017790 s
23          N: 58880            Time: 0.018598 s
24          N: 61440            Time: 0.019410 s
25          N: 64000            Time: 0.020210 s

Zdůvodněte:

K zrychlení dochází kvůli tomu, že hodnoty jsou načteny do sdílené paměti. Ta se nachází přímo na čipu, což vede k paměťovým transakcím, které jsou mnohem rychlejší.


Krok 5: analýza výkonu
======================
N            čas CPU [s]    čas GPU [s]    propustnost paměti [MB/s]    výkon [MFLOPS]    zrychlení [-]     vláken/blok [-]
2048         0.057312       0.000383       168.0847998                  231565.876291     149.64            128
4096         0.227922       0.000756       157.6201063                  469240.058354     301.48            128
8192         0.910145       0.001507       152.2463123                  940971.295509     603.94            128
16384        3.63661        0.003152       141.8817076                  1792976.797289    1153.75           256
32768        14.546         0.007027       125.8875108                  3226779.399985    2070.02           128
65536        58.1601        0.018751       93.8731372                   4836760.762754    3101.71           128
131072       232.677        0.069807       50.2811866                   5180199.309682    3333.15           256
262144       930.494        0.263188       27.0847157                   5495805.456708    3535.47           256
524288       4*930.494      0.990323       23.1190601                   5828235.045855    3758.35           1024
1048576      16*930.494     3.809705       144.4789406                  6064947.392854    3907.89           512

Propustnosti a výkon GPU byly měřeny pomoci: https://gitlab.com/NERSC/roofline-on-nvidia-gpus/-/tree/roofline-hackathon-2020/

čas [s] =  sm__cycles_elapsed.avg / sm__cycles_elapsed.avg.per_second

propustnost paměti [MB/s] = dram__bytes.sum.per_second / 1024 / 1024

výkon [MFLOP/S] = (2 * sm__sass_thread_inst_executed_op_dfma_pred_on.sum + sm__sass_thread_inst_executed_op_dmul_pred_on.sum + sm__sass_thread_inst_executed_op_dadd_pred_on.sum + 2 * sm__sass_thread_inst_executed_op_ffma_pred_on. + sm__sass_thread_inst_executed_op_fmul_pred_on.sum +
    + sm__sass_thread_inst_executed_op_fadd_pred_on.sum + 2 * sm__sass_thread_inst_executed_op_hfma_pred_on.sum + sm__sass_thread_inst_executed_op_hmul_pred_on.sum + sm__sass_thread_inst_executed_op_hadd_pred_on.sum + 512 * sm__inst_executed_pipe_tensor.sum) / čas / 1024 / 1024

Od jakého počtu částic se vyplatí počítat na grafické kartě?

Díky úpravám a zjednodušení výpočtu, se vyplatí počítat na grafické kartě již od nejmenšího počtu částic.

Krok 5: bonus - srovnání grafických karet
======================
N            čas GPU 1 [s]   propustnost 1 [MB/s]    výkon 1 [MFLOPS]   čas GPU 2 [s]  propustnost 2 [MB/s]    výkon 2 [MFLOPS]
2048         0.000383        168.0847998             231565.876291      0.000317       192.75883101            278232.726236
4096         0.000756        157.6201063             469240.058354      0.000624       185.52908926            564653.474178
8192         0.001507        152.2463123             940971.295509      0.001238       181.97615196            1137360.804103
16384        0.003152        141.8817076             1792976.797289     0.002632       175.84464311            2139808.202375
32768        0.007027        125.8875108             3226779.399985     0.006452       136.62503140            3492016.071422
65536        0.018751        93.8731372              4836760.762754     0.019079       102.30352696            4723279.627004
131072       0.069807        50.2811866              5180199.309682     0.087078       118.56649683            4139446.314477
262144       0.263188        27.0847157              5495805.456708     0.323410       98.93905934             4458135.291475
524288       0.990323        23.1190601              5828235.045855     1.191340       105.78658600            4840929.571209
1048576      3.809705        144.4789406             6064947.392854     4.475398       110.28927158            5154563.847088

Porovnejte grafické karty z hlediska výkonu a propustnosti paměti.

Nvidia V100 [GPU 2] je rychlejší na menších vstupech, jako možné vysvětlení lze považovat vyšší frekvenci teto karty v base režimu (1245 MHz vs. 1095 MHz). Na větších vstupech již však dominuje A100 [GPU 1], která disponuje více SM jednotkami.

===================================
